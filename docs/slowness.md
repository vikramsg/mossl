# HTTPS GET Slowness Notes

This document captures why `make test-https`/`tests/test_https_get.mojo` can feel slow even when all sites pass.

## Benchmarks (Jan 5, 2026)

We benchmarked core crypto operations to identify bottlenecks. The following output was generated by running `bash bench/run.sh`.

```text
---------------------------------------------------
Running Mojo Benchmarks...
RSA-2048 Verify (Mojo): 1759.82 ops/sec
ECDSA P-384 Verify (Mojo): 1.16 ops/sec
BigInt ModPow (2048-bit) (Mojo): 1830.15 ops/sec
---------------------------------------------------
Running Python Benchmarks (Reference)...
RSA-2048 Verify (Python): 64695.07 ops/sec
ECDSA P-384 Verify (Python): 4657.50 ops/sec
BigInt ModPow (2048-bit) (Python): 3316.29 ops/sec
---------------------------------------------------
```

## Conclusions (Initial)

- **Critical Bottleneck: ECDSA P-384**: Verifying a single ECDSA P-384 signature in Mojo takes ~0.86 seconds (~1.16 ops/sec). Compared to Python's optimized native implementation (4657 ops/sec), Mojo is **~4000x slower**. This is definitively the primary cause of slowness.
- **RSA Performance**: Mojo's RSA is significantly slower than native (~1,760 vs ~64,700 ops/sec), but ~1.7k ops/sec is acceptable for typical test loads and not the blocking factor.
- **BigInt Performance**: Mojo's BigInt modular exponentiation is roughly 2x slower than Python (1830 vs 3316 ops/sec), which is reasonable given it's a pure software implementation.

## Investigation Update (Jan 5, 2026 - Part 2)

After optimizing ECDSA P-384 and P-256 using windowed scalar multiplication and Montgomery arithmetic, we re-ran the benchmarks and instrumented the HTTPS client.

### 1. ECDSA Performance is Excellent

Instrumented logs from `bench/v2/` show that generic elliptic curve math is no longer a bottleneck.

**Breakdown of `verify_ecdsa_p256` (~0.4ms total):**
- `mont_pow` (modular inversion): **~0.03ms**
- `double_scalar_mul_windowed`: **~0.27ms**
- Total `verify_generic`: **< 0.5ms**

**Impact on Handshake:**
- `handle_cert_verify`: **~0.4ms**
- `verify_chain` (parsing + sig verify): **~2ms - 5ms**
- `perform_handshake_total`: **~30ms - 50ms** (excluding network I/O)

### 2. AES-GCM is the Dominant CPU Bottleneck (~1.5 MB/s)

My benchmarks confirm that `aes_gcm.mojo` is performing at approximately **1.5 MB/s**. While this sounds fast enough for small pages, the overhead in Mojo's current implementation is significant:
- **Redundant Key Expansion**: `aes_encrypt_block` re-runs `key_expansion` for every single 16-byte block. A 100KB transfer triggers ~6,250 key expansions.
- **GF Multiplication**: `ghash` uses a bit-by-bit `gf_mul` (128 iterations) for every block.
- **Allocation Overhead**: High frequency of `List` allocations for intermediate states and S-Box lookups creates significant pressure on the Mojo runtime.

In `make test-https`, which processes dozens of records across 10 sites (including large certificate lists and response bodies), this low throughput accounts for the majority of the **14s user time**.

### 3. Trust Store Loading is Negligible

Initial concerns about trust store loading were investigated. Benchmarks show that loading and parsing the system trust store (~150 certificates) takes less than **10ms**. Since this happens once per handshake, it contributes less than 1% to the total request time.

## Conclusions (Final)

The primary CPU bottleneck of unoptimized ECDSA has been **resolved**. **AES-GCM throughput** is now the only significant cryptographic bottleneck remaining.

| Operation | Latency / Throughput | Status |
| :--- | :--- | :--- |
| **ECDSA P-256 Verify** | **~0.4ms** | Optimized |
| **ECDSA P-384 Verify** | **~0.8ms** | Optimized |
| **Trust Store Loading** | **~2ms - 10ms** | Negligible |
| **Full TLS Handshake** | **~40ms** | Optimized |
| **AES-GCM Throughput** | **~1.5 MB/sec** | **Bottleneck** |

## Future Optimization Work

1.  **Optimize AES-GCM**:
    *   Pre-compute expanded round keys once per record (or once per session).
    *   Implement table-based GF multiplication or use SIMD-accelerated carries if available.
    *   Use `InlineArray` or `UnsafePointer` to eliminate `List` allocations in the hot path.
2.  **Connection Reuse**: Support `Keep-Alive` to avoid repeated handshakes and key setups in integration tests.